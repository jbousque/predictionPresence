{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import config\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "logger = logging.getLogger()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "\n",
    "# random forests\n",
    "param_grid_rf =  {\n",
    "    'n_estimators' : [10, 20, 30, 40, 50, 100, 1000],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "    \"max_depth\": [None, 2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 5, 10]\n",
    "}\n",
    "\n",
    "# SVM\n",
    "param_grid_svm = {\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "    'C': np.logspace(-2, 1, 4),\n",
    "    'gamma': np.logspace(-3, 1, 5)\n",
    "}\n",
    "\n",
    "forest = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "svm = make_pipeline(StandardScaler(), SVC(random_state=RANDOM_STATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data - phases split ...\n",
      "   Subject: 83 samples\n",
      "   Agent: 95 samples\n",
      "   Merge: 81 samples (common to subject and agent)\n",
      "   Subject merged check: 81\n",
      "   Agent merged check: 81\n",
      "   Subject(no phase): 86 samples\n",
      "   Agent(no phase): 92 samples\n",
      "   Merge: 81 samples (common to subject and agent)\n",
      "   Subject merged check: 81\n",
      "   Agent merged check: 81\n"
     ]
    }
   ],
   "source": [
    "matrix_subject_phases = os.path.join('..', 'features', 'matrix-2019-0226_15-16-44Features-157015.xlsx')\n",
    "matrix_agent_phases = os.path.join('..', 'features', 'matrix-2019-0226_17-18-28Features-agent-157015.xlsx')\n",
    "matrix_subject_nophase = os.path.join('..', 'features', 'matrix-2019-0227_20-11-53Features-nophase.xlsx')\n",
    "matrix_agent_nophase = os.path.join('..', 'features', 'matrix-2019-0227_22-43-15Features-agent-nophase.xlsx') \n",
    "\n",
    "def prepare_df(df):\n",
    "    df = df.drop(['Presence Score', 'Co-presence Score'], axis=1)\n",
    "    df = df.rename(index=str,\n",
    "                   columns={\"Presence Class\": \"PresenceClass\", \"Co-presence Class\": \"CopresenceClass\"})\n",
    "    return df\n",
    "\n",
    "def dfval(df, candidate, environment, column):\n",
    "    return df.query(\"Candidate == '%s' & Environment == '%s'\" % (candidate, environment))[column].values\n",
    "\n",
    "print(\"Loading data - phases split ...\")\n",
    "\n",
    "subject_p_df = pd.read_excel(matrix_subject_phases)\n",
    "subject_p_df = prepare_df(subject_p_df)\n",
    "print(\"   Subject: %d samples\" % len(subject_p_df))\n",
    "agent_p_df = pd.read_excel(matrix_agent_phases)\n",
    "agent_p_df = prepare_df(agent_p_df)\n",
    "print(\"   Agent: %d samples\" % len(agent_p_df))\n",
    "\n",
    "all_p_df = pd.merge(subject_p_df, agent_p_df, on=['Candidate', 'Environment'], how='inner', suffixes=('', '_agent'))\n",
    "all_p_df = all_p_df.drop(['PresenceClass_agent', 'CopresenceClass_agent', 'Duration_agent', 'Expert_agent'], axis=1)\n",
    "print(\"   Merge: %d samples (common to subject and agent)\" % len(all_p_df))\n",
    "\n",
    "subject_p_df = pd.merge(subject_p_df, all_p_df, on=['Candidate', 'Environment'], how='inner', suffixes=('', '_toberemoved'))\n",
    "subject_p_df = subject_p_df.drop([col for col in subject_p_df.columns if col.endswith('_toberemoved') ], axis=1)\n",
    "print(\"   Subject merged check: %s\" % len(subject_p_df))\n",
    "\n",
    "agent_p_df = pd.merge(agent_p_df, all_p_df, on=['Candidate', 'Environment'], how='inner', suffixes=('', '_toberemoved'))\n",
    "# computed duration is different for agent but this is due to how it's computed, let it be the same value as for subject\n",
    "agent_p_df = agent_p_df.drop(['Duration'], axis=1)\n",
    "agent_p_df = agent_p_df.rename(index=str, columns={'Duration_toberemoved': 'Duration'})\n",
    "agent_p_df = agent_p_df.drop([col for col in agent_p_df.columns if col.endswith('_toberemoved')], axis=1)\n",
    "print(\"   Agent merged check: %s\" % len(agent_p_df))\n",
    "\n",
    "# no phase\n",
    "\n",
    "subject_np_df = pd.read_excel(matrix_subject_nophase)\n",
    "subject_np_df = prepare_df(subject_np_df)\n",
    "print(\"   Subject(no phase): %d samples\" % len(subject_np_df))\n",
    "agent_np_df = pd.read_excel(matrix_agent_nophase)\n",
    "agent_np_df = prepare_df(agent_np_df)\n",
    "print(\"   Agent(no phase): %d samples\" % len(agent_np_df))\n",
    "\n",
    "all_np_df = pd.merge(subject_np_df, agent_np_df, on=['Candidate', 'Environment'], how='inner', suffixes=('', '_agent'))\n",
    "all_np_df = all_np_df.drop(['PresenceClass_agent', 'CopresenceClass_agent', 'Duration_agent', 'Expert_agent'], axis=1)\n",
    "print(\"   Merge: %d samples (common to subject and agent)\" % len(all_np_df))\n",
    "\n",
    "subject_np_df = pd.merge(subject_np_df, all_np_df, on=['Candidate', 'Environment'], how='inner', suffixes=('', '_toberemoved'))\n",
    "subject_np_df = subject_np_df.drop([col for col in subject_np_df.columns if col.endswith('_toberemoved') ], axis=1)\n",
    "print(\"   Subject merged check: %s\" % len(subject_np_df))\n",
    "\n",
    "agent_np_df = pd.merge(agent_np_df, all_np_df, on=['Candidate', 'Environment'], how='inner', suffixes=('', '_toberemoved'))\n",
    "# computed duration is different for agent but this is due to how it's computed, let it be the same value as for subject\n",
    "agent_np_df = agent_np_df.drop(['Duration'], axis=1)\n",
    "agent_np_df = agent_np_df.rename(index=str, columns={'Duration_toberemoved': 'Duration'})\n",
    "agent_np_df = agent_np_df.drop([col for col in agent_np_df.columns if col.endswith('_toberemoved')], axis=1)\n",
    "print(\"   Agent merged check: %s\" % len(agent_np_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Expert', 'Head_Entropy_Start', 'Head_Entropy_Mid', 'Head_Entropy_End', 'Avg_HandEntropy_Begin', 'Avg_HandEntropy_Mid', 'Avg_HandEntropy_End', 'Avg_SentenceLength_Begin', 'Avg_SentenceLength_Mid', 'Avg_SentenceLength_End', 'Ratio1_Begin', 'Ratio1_Mid', 'Ratio1_End', 'Ratio2_Begin', 'Ratio2_Mid', 'Ratio2_End', 'Duration', 'Head_Entropy_Start_agent', 'Head_Entropy_Mid_agent', 'Head_Entropy_End_agent', 'Avg_HandEntropy_Begin_agent', 'Avg_HandEntropy_Mid_agent', 'Avg_HandEntropy_End_agent', 'Avg_SentenceLength_Begin_agent', 'Avg_SentenceLength_Mid_agent', 'Avg_SentenceLength_End_agent', 'Ratio1_Begin_agent', 'Ratio1_Mid_agent', 'Ratio1_End_agent', 'Ratio2_Begin_agent', 'Ratio2_Mid_agent', 'Ratio2_End_agent')\n",
      "('Expert', 'Head_Entropy_Mid', 'Avg_HandEntropy_Mid', 'Avg_SentenceLength_Mid', 'Ratio1_Mid', 'Ratio2_Mid', 'Duration', 'Head_Entropy_Start_agent', 'Head_Entropy_Mid_agent', 'Head_Entropy_End_agent', 'Avg_HandEntropy_Begin_agent', 'Avg_HandEntropy_Mid_agent', 'Avg_HandEntropy_End_agent', 'Avg_SentenceLength_Begin_agent', 'Avg_SentenceLength_Mid_agent', 'Avg_SentenceLength_End_agent', 'Ratio1_Begin_agent', 'Ratio1_Mid_agent', 'Ratio1_End_agent', 'Ratio2_Begin_agent', 'Ratio2_Mid_agent', 'Ratio2_End_agent')\n"
     ]
    }
   ],
   "source": [
    "# todo \"Avg_IPUlen_Begin\", \"Avg_IPUlen_Middle\", \"Avg_IPUlen_End\" removed because of wrong values\n",
    "subject_features = (\"Expert\", \"Head_Entropy_Start\", \"Head_Entropy_Mid\", \"Head_Entropy_End\", \"Avg_HandEntropy_Begin\",\n",
    "             \"Avg_HandEntropy_Mid\", \"Avg_HandEntropy_End\", \"Avg_SentenceLength_Begin\", \"Avg_SentenceLength_Mid\",\n",
    "             \"Avg_SentenceLength_End\",  \"Ratio1_Begin\", \"Ratio1_Mid\", \"Ratio1_End\", \"Ratio2_Begin\", \"Ratio2_Mid\", \n",
    "                    \"Ratio2_End\", \"Duration\")\n",
    "\n",
    "# not using \"Expert\" feature for agent features\n",
    "agent_features = (\"Head_Entropy_Start\", \"Head_Entropy_Mid\", \"Head_Entropy_End\", \"Avg_HandEntropy_Begin\",\n",
    "             \"Avg_HandEntropy_Mid\", \"Avg_HandEntropy_End\", \"Avg_SentenceLength_Begin\", \"Avg_SentenceLength_Mid\",\n",
    "             \"Avg_SentenceLength_End\",  \"Ratio1_Begin\", \"Ratio1_Mid\", \"Ratio1_End\", \"Ratio2_Begin\", \"Ratio2_Mid\", \n",
    "                    \"Ratio2_End\", \"Duration\")\n",
    "\n",
    "all_features = subject_features + tuple(feat+'_agent' for feat in agent_features if feat is not 'Duration')\n",
    "\n",
    "subject_features_nophase = (\"Expert\", \"Head_Entropy_Mid\", \"Avg_HandEntropy_Mid\", \"Avg_SentenceLength_Mid\", \"Ratio1_Mid\", \n",
    "                            \"Ratio2_Mid\", \"Duration\")\n",
    "\n",
    "agent_features_nophase = (\"Head_Entropy_Mid\", \"Avg_HandEntropy_Mid\", \"Avg_SentenceLength_Mid\", \"Ratio1_Mid\", \n",
    "                            \"Ratio2_Mid\", \"Duration\")\n",
    "\n",
    "all_features_nophase = subject_features_nophase + tuple(feat+'_agent' for feat in agent_features if feat is not 'Duration')\n",
    "\n",
    "# verbal features\n",
    "\n",
    "subject_features_verbal = (\"Head_Entropy_Mid\", \"Avg_HandEntropy_Mid\", \"Avg_SentenceLength_Mid\", \"Ratio1_Mid\", \n",
    "                            \"Ratio2_Mid\")\n",
    "\n",
    "agent_features_verbal = (\"Head_Entropy_Mid\", \"Avg_HandEntropy_Mid\", \"Avg_SentenceLength_Mid\", \"Ratio1_Mid\", \n",
    "                            \"Ratio2_Mid\")\n",
    "\n",
    "all_features_verbal = subject_features_nophase + tuple(feat+'_agent' for feat in agent_features if feat is not 'Duration')\n",
    "\n",
    "# non-verbal features\n",
    "\n",
    "subject_features_nonverbal = (\"Head_Entropy_Mid\", \"Avg_HandEntropy_Mid\", \"Avg_SentenceLength_Mid\", \"Ratio1_Mid\", \n",
    "                            \"Ratio2_Mid\")\n",
    "\n",
    "agent_features_nonverbal = (\"Head_Entropy_Mid\", \"Avg_HandEntropy_Mid\", \"Avg_SentenceLength_Mid\", \"Ratio1_Mid\", \n",
    "                            \"Ratio2_Mid\")\n",
    "\n",
    "all_features_nonverbal = subject_features_nophase + tuple(feat+'_agent' for feat in agent_features if feat is not 'Duration')\n",
    "\n",
    "out_path = os.path.join(config.OUT_PATH, 'gridsearchcv')\n",
    "if not os.path.exists(out_path): os.makedirs(out_path)\n",
    "\n",
    "def gscv_name(presence=True, doctor=True, agent=False, phases=None, classifier='RF'):\n",
    "    pres = 'presence' if presence else 'copresence'\n",
    "    subject = 'doctor' if doctor else ''\n",
    "    subject = subject + ('agent' if agent else '')\n",
    "    ph = 'nophase' if phases is None else '%d%d%d' % ( phases[0]*100, phases[1]*100, phases[2]*100 )\n",
    "    return \"%s_%s_%s_%s\" % (pres, subject, ph, classifier)\n",
    "\n",
    "def save_gscv(grid, presence=True, doctor=True, agent=False, phases=None, classifier='RF'):\n",
    "    name = \"grid_%s.pkl\" % (gscv_name(presence, doctor, agent, phases, classifier))\n",
    "    f = open(os.path.join(out_path, name), 'wb')\n",
    "    pickle.dump(grid, f)\n",
    "    f.close()\n",
    "    \n",
    "def load_gscv(presence=True, doctor=True, phases=None, classifier='RF'):\n",
    "    name = \"grid_%s.pkl\" % (gscv_name(presence, doctor, agent, phases, classifier))\n",
    "    f = open(os.path.join(out_path, name), 'rb')\n",
    "    grid = pickle.load(f)\n",
    "    f.close()\n",
    "    return grid\n",
    "\n",
    "def save_results(rdf):\n",
    "    try:\n",
    "        frdf_name = 'results.pkl'\n",
    "        frdf = open(os.path.join(out_path, frdf_name), 'wb')\n",
    "        pickle.dump(rdf, frdf)\n",
    "        frdf.close()\n",
    "    except Exception as e:\n",
    "        print('Could not save results file %s' % (os.path.join(out_path, frdf_name)))\n",
    "        print(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def load_results():\n",
    "    try:\n",
    "        frdf_name = 'results.pkl'\n",
    "        frdf = open(os.path.join(out_path, frdf_name), 'rb')\n",
    "        rdf = pickle.load(frdf)\n",
    "        frdf.close()\n",
    "    except Exception:\n",
    "        print('results file does not yet exist')\n",
    "        return None\n",
    "    return rdf\n",
    "\n",
    "def prepare_train_data(samples, modelTarget, features, upsample=False):\n",
    "    \n",
    "    names = features\n",
    "    \n",
    "    samples_split = []\n",
    "    if (modelTarget == \"presence\"):\n",
    "        samples_split.append(samples[samples.PresenceClass == 1])\n",
    "        samples_split.append(samples[samples.PresenceClass == 2])\n",
    "        samples_split.append(samples[samples.PresenceClass == 3])\n",
    "\n",
    "    elif (modelTarget == \"copresence\"):\n",
    "        samples_split.append(samples[samples.CopresenceClass == 1])\n",
    "        samples_split.append(samples[samples.CopresenceClass == 2])\n",
    "        samples_split.append(samples[samples.CopresenceClass == 3])\n",
    "    else:\n",
    "        sys.exit(\"Invalid input. Please pick between presence and copresence\")\n",
    "\n",
    "    maxClassSize = max(samples_split[0].shape[0], samples_split[1].shape[0], samples_split[2].shape[0])\n",
    "\n",
    "    if upsample:\n",
    "        upsampled = []\n",
    "        # todo upsample with SMOTE algorithm ? https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html\n",
    "        for idx, samples in enumerate(samples_split):\n",
    "            if (samples.shape[0] == maxClassSize):\n",
    "                upsampled.append(samples)\n",
    "            else:\n",
    "                logger.debug(\"resample: adding \" + str(maxClassSize - samples.shape[0]) + \" samples to class \" + str(\n",
    "                    idx + 1) + \" to reach \" + str(maxClassSize))\n",
    "                upsampled.append(resample(samples, replace=True, n_samples=maxClassSize, random_state=None))\n",
    "\n",
    "        balanced_set = pd.concat(upsampled)\n",
    "        X = np.nan_to_num(balanced_set.as_matrix(names))\n",
    "\n",
    "        if (modelTarget == \"presence\"):\n",
    "            y = np.array(balanced_set[\"PresenceClass\"].tolist())\n",
    "\n",
    "        else:\n",
    "            y = np.array(balanced_set[\"CopresenceClass\"].tolist())\n",
    "\n",
    "    else:\n",
    "\n",
    "        X = np.nan_to_num(samples[list(names)])\n",
    "        if modelTarget == \"presence\":\n",
    "            y = samples.PresenceClass\n",
    "        else:\n",
    "            y = samples.CopresenceClass\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "def gridsearch(clf, X, y, modelTarget, param_grid, features, upsample=False, verbose=1):\n",
    "    #print(\"gridsearch(clf=%s, modelTarget=%s, param_grid=%s, features=%s, upsample=%s)\" \n",
    "    #      % (type(clf), modelTarget, param_grid, features, upsample))\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    #logger.debug(\"X_train \", X_train.shape, \"X_test\", X_test.shape, \"y_train\", y_train.shape, \"y_test\", y_test.shape)\n",
    "\n",
    "  # todo move to beginning with other imports\n",
    "\n",
    "    #n_estimators = np.concatenate((np.arange(1,10), np.arange(10,100,10)))\n",
    "    print(np.unique(y, return_counts=True))\n",
    "    grid = GridSearchCV(estimator=clf, param_grid=param_grid,\n",
    "                        scoring=['f1_macro', 'precision_macro', 'recall_macro'],\n",
    "                        refit='f1_macro',\n",
    "                        cv=10,\n",
    "                        return_train_score=True,\n",
    "                        verbose=verbose)\n",
    "\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    results = grid.cv_results_\n",
    "    # print(\"best params \", grid.best_params_)\n",
    "    # print(\"best score \", grid.best_score_)\n",
    "\n",
    "    return grid\n",
    "\n",
    "def run_cross_val_score(clf, X, y, modelTarget, param_grid, features, upsample=False, verbose=1):\n",
    "    #print(\"gridsearch(clf=%s, modelTarget=%s, param_grid=%s, features=%s, upsample=%s)\" \n",
    "    #      % (type(clf), modelTarget, param_grid, features, upsample))\n",
    "\n",
    "    return cross_validate(clf, X, y, scoring=['f1_macro', 'precision_macro', 'recall_macro', 'f1'], cv=10, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Phases</th>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Presence</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Doctor</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.816032</td>\n",
       "      <td>0.776039</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 50, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.843900</td>\n",
       "      <td>0.801139</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.778753</td>\n",
       "      <td>0.723586</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 40, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.927302</td>\n",
       "      <td>0.892880</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Agent</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.763946</td>\n",
       "      <td>0.733961</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 30, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.818995</td>\n",
       "      <td>0.784713</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.810794</td>\n",
       "      <td>0.754127</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 20, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.883039</td>\n",
       "      <td>0.793964</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Doctor+Agent</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.808904</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 40, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.898753</td>\n",
       "      <td>0.843911</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.782381</td>\n",
       "      <td>0.747407</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 50, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.913515</td>\n",
       "      <td>0.862339</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Co-Presence</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Doctor</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.821652</td>\n",
       "      <td>0.798101</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 30, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.897212</td>\n",
       "      <td>0.821709</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.843895</td>\n",
       "      <td>0.775644</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 10, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.855305</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Agent</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.916809</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 30, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.920391</td>\n",
       "      <td>0.870184</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.857977</td>\n",
       "      <td>0.843006</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 40, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.919678</td>\n",
       "      <td>0.882360</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Doctor+Agent</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.827934</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 10, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.890761</td>\n",
       "      <td>0.862064</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.891758</td>\n",
       "      <td>0.857478</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 100, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.891209</td>\n",
       "      <td>0.858275</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  precision        f1  \\\n",
       "Metric      Subject      Phases   Classifier                            \n",
       "Presence    Doctor       No Phase Random Forests   0.816032  0.776039   \n",
       "                                  SVM              0.843900  0.801139   \n",
       "                         157015   Random Forests   0.778753  0.723586   \n",
       "                                  SVM              0.927302  0.892880   \n",
       "            Agent        No Phase Random Forests   0.763946  0.733961   \n",
       "                                  SVM              0.818995  0.784713   \n",
       "                         157015   Random Forests   0.810794  0.754127   \n",
       "                                  SVM              0.883039  0.793964   \n",
       "            Doctor+Agent No Phase Random Forests   0.844444  0.808904   \n",
       "                                  SVM              0.898753  0.843911   \n",
       "                         157015   Random Forests   0.782381  0.747407   \n",
       "                                  SVM              0.913515  0.862339   \n",
       "Co-Presence Doctor       No Phase Random Forests   0.821652  0.798101   \n",
       "                                  SVM              0.897212  0.821709   \n",
       "                         157015   Random Forests   0.843895  0.775644   \n",
       "                                  SVM              0.881481  0.855305   \n",
       "            Agent        No Phase Random Forests   0.916809  0.893617   \n",
       "                                  SVM              0.920391  0.870184   \n",
       "                         157015   Random Forests   0.857977  0.843006   \n",
       "                                  SVM              0.919678  0.882360   \n",
       "            Doctor+Agent No Phase Random Forests   0.868091  0.827934   \n",
       "                                  SVM              0.890761  0.862064   \n",
       "                         157015   Random Forests   0.891758  0.857478   \n",
       "                                  SVM              0.891209  0.858275   \n",
       "\n",
       "                                                    recall  \\\n",
       "Metric      Subject      Phases   Classifier                 \n",
       "Presence    Doctor       No Phase Random Forests  0.780952   \n",
       "                                  SVM             0.809524   \n",
       "                         157015   Random Forests  0.742857   \n",
       "                                  SVM             0.895238   \n",
       "            Agent        No Phase Random Forests  0.742857   \n",
       "                                  SVM             0.809524   \n",
       "                         157015   Random Forests  0.771429   \n",
       "                                  SVM             0.800000   \n",
       "            Doctor+Agent No Phase Random Forests  0.819048   \n",
       "                                  SVM             0.847619   \n",
       "                         157015   Random Forests  0.752381   \n",
       "                                  SVM             0.866667   \n",
       "Co-Presence Doctor       No Phase Random Forests  0.803419   \n",
       "                                  SVM             0.837607   \n",
       "                         157015   Random Forests  0.794872   \n",
       "                                  SVM             0.871795   \n",
       "            Agent        No Phase Random Forests  0.897436   \n",
       "                                  SVM             0.880342   \n",
       "                         157015   Random Forests  0.846154   \n",
       "                                  SVM             0.888889   \n",
       "            Doctor+Agent No Phase Random Forests  0.837607   \n",
       "                                  SVM             0.880342   \n",
       "                         157015   Random Forests  0.863248   \n",
       "                                  SVM             0.871795   \n",
       "\n",
       "                                                                                             params  \n",
       "Metric      Subject      Phases   Classifier                                                         \n",
       "Presence    Doctor       No Phase Random Forests  {'max_features': 'auto', 'n_estimators': 50, '...  \n",
       "                                  SVM                    {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}  \n",
       "                         157015   Random Forests  {'max_features': 'auto', 'n_estimators': 40, '...  \n",
       "                                  SVM                     {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}  \n",
       "            Agent        No Phase Random Forests  {'max_features': None, 'n_estimators': 30, 'cl...  \n",
       "                                  SVM                    {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}  \n",
       "                         157015   Random Forests  {'max_features': None, 'n_estimators': 20, 'cl...  \n",
       "                                  SVM                     {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}  \n",
       "            Doctor+Agent No Phase Random Forests  {'max_features': None, 'n_estimators': 40, 'cl...  \n",
       "                                  SVM                     {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}  \n",
       "                         157015   Random Forests  {'max_features': 'auto', 'n_estimators': 50, '...  \n",
       "                                  SVM                     {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}  \n",
       "Co-Presence Doctor       No Phase Random Forests  {'max_features': 'auto', 'n_estimators': 30, '...  \n",
       "                                  SVM                     {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}  \n",
       "                         157015   Random Forests  {'max_features': None, 'n_estimators': 10, 'cl...  \n",
       "                                  SVM                     {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}  \n",
       "            Agent        No Phase Random Forests  {'max_features': 'auto', 'n_estimators': 30, '...  \n",
       "                                  SVM                     {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}  \n",
       "                         157015   Random Forests  {'max_features': None, 'n_estimators': 40, 'cl...  \n",
       "                                  SVM                     {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}  \n",
       "            Doctor+Agent No Phase Random Forests  {'max_features': 'auto', 'n_estimators': 10, '...  \n",
       "                                  SVM                     {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}  \n",
       "                         157015   Random Forests  {'max_features': 'auto', 'n_estimators': 100, ...  \n",
       "                                  SVM                     {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare results\n",
    "def update_results(cv_results_, rdf, p1, p2, p3, p4):\n",
    "    df = pd.DataFrame(cv_results_)\n",
    "    best_precision = df.mean_test_precision_macro.max()\n",
    "    df_best = df.loc[df['mean_test_precision_macro'] == best_precision]\n",
    "    rdf.at[(p1, p2, p3, p4), 'precision'] = df_best.mean_test_precision_macro.values[0]\n",
    "    rdf.at[(p1, p2, p3, p4), 'f1'] = df_best.mean_test_f1_macro.values[0]\n",
    "    rdf.at[(p1, p2, p3, p4), 'recall'] = df_best.mean_test_recall_macro.values[0]\n",
    "    rdf.at[(p1, p2, p3, p4), 'params'] = str(df_best.params.values[0])\n",
    "    #print(\"%s %s %s %s %s\" % (p1, p2, p3, p4, str(rdf.at[p1, p2, p3, p4])))\n",
    "    save_results(rdf)\n",
    "    return rdf\n",
    "\n",
    "rdf_index = [['Presence', 'Co-Presence'], ['Doctor', 'Agent', 'Doctor+Agent'], ['No Phase', '157015'], ['Random Forests', 'SVM']]\n",
    "rdf_columns = ['precision', 'f1', 'recall', 'params']\n",
    "rdf_multiindex = pd.MultiIndex.from_product(rdf_index, names=['Metric', 'Subject', 'Phases', 'Classifier'])\n",
    "\n",
    "rdf = load_results()\n",
    "if rdf is None:\n",
    "    rdf = pd.DataFrame(np.zeros((24,4)), index=rdf_multiindex, columns=rdf_columns)\n",
    "    rdf['params'] = rdf['params'].apply(str)\n",
    "    rdf['params'] = ''\n",
    "    save_results(rdf)\n",
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 tests to be performed\n",
      "{'phases': (0.15, 0.7, 0.15), 'target': 'presence', 'classifier': 'svm', 'subject': 'doctor'}\n",
      "{'phases': (0.15, 0.7, 0.15), 'target': 'copresence', 'classifier': 'svm', 'subject': 'doctor'}\n",
      "{'phases': (0.15, 0.7, 0.15), 'target': 'presence', 'classifier': 'svm', 'subject': 'agent'}\n",
      "{'phases': (0.15, 0.7, 0.15), 'target': 'copresence', 'classifier': 'svm', 'subject': 'agent'}\n",
      "{'phases': (0.15, 0.7, 0.15), 'target': 'presence', 'classifier': 'svm', 'subject': 'doctor+agent'}\n",
      "{'phases': (0.15, 0.7, 0.15), 'target': 'copresence', 'classifier': 'svm', 'subject': 'doctor+agent'}\n",
      "{'phases': (0, 1, 0), 'target': 'presence', 'classifier': 'svm', 'subject': 'doctor'}\n",
      "{'phases': (0, 1, 0), 'target': 'copresence', 'classifier': 'svm', 'subject': 'doctor'}\n",
      "{'phases': (0, 1, 0), 'target': 'presence', 'classifier': 'svm', 'subject': 'agent'}\n",
      "{'phases': (0, 1, 0), 'target': 'copresence', 'classifier': 'svm', 'subject': 'agent'}\n",
      "{'phases': (0, 1, 0), 'target': 'presence', 'classifier': 'svm', 'subject': 'doctor+agent'}\n",
      "{'phases': (0, 1, 0), 'target': 'copresence', 'classifier': 'svm', 'subject': 'doctor+agent'}\n"
     ]
    }
   ],
   "source": [
    "# combinations to be ran\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "test_plan_params = {\n",
    "    'classifier': ['svm'],\n",
    "    'subject': ['doctor', 'agent', 'doctor+agent'],\n",
    "    'target': ['presence', 'copresence'],\n",
    "    'phases': [(0.15,0.70,0.15), (0,1,0)]\n",
    "}\n",
    "test_plan = list(ParameterGrid(test_plan_params))\n",
    "print(\"%d tests to be performed\" % len(test_plan))\n",
    "for test in test_plan:\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0 : {'phases': (0.15, 0.7, 0.15), 'target': 'presence', 'classifier': 'svm', 'subject': 'doctor'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Presence Doctor 157015 SVM\n",
      "Test 1 : {'phases': (0.15, 0.7, 0.15), 'target': 'copresence', 'classifier': 'svm', 'subject': 'doctor'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:   39.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Co-Presence Doctor 157015 SVM\n",
      "Test 2 : {'phases': (0.15, 0.7, 0.15), 'target': 'presence', 'classifier': 'svm', 'subject': 'agent'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Presence Agent 157015 SVM\n",
      "Test 3 : {'phases': (0.15, 0.7, 0.15), 'target': 'copresence', 'classifier': 'svm', 'subject': 'agent'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:   45.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Co-Presence Agent 157015 SVM\n",
      "Test 4 : {'phases': (0.15, 0.7, 0.15), 'target': 'presence', 'classifier': 'svm', 'subject': 'doctor+agent'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:   39.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Presence Doctor+Agent 157015 SVM\n",
      "Test 5 : {'phases': (0.15, 0.7, 0.15), 'target': 'copresence', 'classifier': 'svm', 'subject': 'doctor+agent'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:   49.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Co-Presence Doctor+Agent 157015 SVM\n",
      "Test 6 : {'phases': (0, 1, 0), 'target': 'presence', 'classifier': 'svm', 'subject': 'doctor'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:   59.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Presence Doctor No Phase SVM\n",
      "Test 7 : {'phases': (0, 1, 0), 'target': 'copresence', 'classifier': 'svm', 'subject': 'doctor'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Co-Presence Doctor No Phase SVM\n",
      "Test 8 : {'phases': (0, 1, 0), 'target': 'presence', 'classifier': 'svm', 'subject': 'agent'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Presence Agent No Phase SVM\n",
      "Test 9 : {'phases': (0, 1, 0), 'target': 'copresence', 'classifier': 'svm', 'subject': 'agent'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:   53.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Co-Presence Agent No Phase SVM\n",
      "Test 10 : {'phases': (0, 1, 0), 'target': 'presence', 'classifier': 'svm', 'subject': 'doctor+agent'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:   51.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      updating Presence Doctor+Agent No Phase SVM\n",
      "Test 11 : {'phases': (0, 1, 0), 'target': 'copresence', 'classifier': 'svm', 'subject': 'doctor+agent'}\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "      updating Co-Presence Doctor+Agent No Phase SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:   49.9s finished\n"
     ]
    }
   ],
   "source": [
    "for idx, test in enumerate(test_plan):\n",
    "    print(\"Test %d : %s\" % (idx, test))\n",
    "\n",
    "    subject = test['subject']\n",
    "    target = test['target']\n",
    "    phases = test['phases']\n",
    "    classifier = test['classifier']\n",
    "    clf = forest if classifier == 'forest' else svm\n",
    "    pgrid = param_grid if classifier == 'forest' else param_grid_svm\n",
    "\n",
    "    if phases is not None and phases is not (0,1,0):\n",
    "        if subject == 'doctor':\n",
    "            df = subject_p_df\n",
    "            feats = subject_features\n",
    "        elif subject == 'agent':\n",
    "            df = agent_p_df\n",
    "            feats = agent_features\n",
    "        elif subject == 'doctor+agent':\n",
    "            df = all_p_df\n",
    "            feats=all_features\n",
    "    else:\n",
    "        if subject == 'doctor':\n",
    "            df = subject_np_df\n",
    "            feats = subject_features_nophase\n",
    "        elif subject == 'agent':\n",
    "            df = agent_np_df\n",
    "            feats = agent_features_nophase\n",
    "        elif subject == 'doctor+agent':\n",
    "            df = all_np_df\n",
    "            feats=all_features_nophase   \n",
    "    \n",
    "    grid = gridsearch(clf, df, target, param_grid=pgrid, features=feats, upsample=True)\n",
    "    \n",
    "    isDoc = 'doctor' in subject\n",
    "    isAgent = 'agent' in subject\n",
    "    save_gscv(grid, presence=target=='presence', doctor=isDoc, agent=isAgent,\n",
    "             phases=phases, classifier='RF' if test['classifier']=='forest' else 'SVM')\n",
    "    \n",
    "    presidx = 'Presence' if target == 'presence' else 'Co-Presence'\n",
    "    if subject == 'doctor':\n",
    "        subjidx = 'Doctor'\n",
    "    elif subject == 'agent':\n",
    "        subjidx = 'Agent'\n",
    "    else:\n",
    "        subjidx = 'Doctor+Agent'\n",
    "    phidx = 'No Phase' if phases in [None, (0,1,0)] else '%2d%2d%2d' % ( phases[0]*100, phases[1]*100, phases[2]*100 )\n",
    "    clfidx = 'Random Forests' if classifier == 'forest' else 'SVM'\n",
    "    print(\"      updating %s %s %s %s\" % (presidx, subjidx, phidx, clfidx))\n",
    "    rdf = update_results(grid.cv_results_, rdf, presidx, subjidx, phidx, clfidx)\n",
    "    dumpPath = os.path.join(config.OUT_PATH, 'gridsearchcv', 'results.xlsx')\n",
    "    rdf.to_excel(dumpPath, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Phases</th>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Presence</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Doctor</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.896508</td>\n",
       "      <td>0.852215</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 40, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Agent</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.798254</td>\n",
       "      <td>0.762850</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 50, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Doctor+Agent</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.856372</td>\n",
       "      <td>0.784093</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>{'max_features': 'log2', 'n_estimators': 10, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Co-Presence</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Doctor</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Agent</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Doctor+Agent</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Phase</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">157015</th>\n",
       "      <th>Random Forests</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  precision        f1  \\\n",
       "Metric      Subject      Phases   Classifier                            \n",
       "Presence    Doctor       No Phase Random Forests   0.000000  0.000000   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "                         157015   Random Forests   0.896508  0.852215   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "            Agent        No Phase Random Forests   0.000000  0.000000   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "                         157015   Random Forests   0.798254  0.762850   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "            Doctor+Agent No Phase Random Forests   0.000000  0.000000   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "                         157015   Random Forests   0.856372  0.784093   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "Co-Presence Doctor       No Phase Random Forests   0.000000  0.000000   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "                         157015   Random Forests   0.000000  0.000000   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "            Agent        No Phase Random Forests   0.000000  0.000000   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "                         157015   Random Forests   0.000000  0.000000   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "            Doctor+Agent No Phase Random Forests   0.000000  0.000000   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "                         157015   Random Forests   0.000000  0.000000   \n",
       "                                  SVM              0.000000  0.000000   \n",
       "\n",
       "                                                    recall  \\\n",
       "Metric      Subject      Phases   Classifier                 \n",
       "Presence    Doctor       No Phase Random Forests  0.000000   \n",
       "                                  SVM             0.000000   \n",
       "                         157015   Random Forests  0.857143   \n",
       "                                  SVM             0.000000   \n",
       "            Agent        No Phase Random Forests  0.000000   \n",
       "                                  SVM             0.000000   \n",
       "                         157015   Random Forests  0.771429   \n",
       "                                  SVM             0.000000   \n",
       "            Doctor+Agent No Phase Random Forests  0.000000   \n",
       "                                  SVM             0.000000   \n",
       "                         157015   Random Forests  0.800000   \n",
       "                                  SVM             0.000000   \n",
       "Co-Presence Doctor       No Phase Random Forests  0.000000   \n",
       "                                  SVM             0.000000   \n",
       "                         157015   Random Forests  0.000000   \n",
       "                                  SVM             0.000000   \n",
       "            Agent        No Phase Random Forests  0.000000   \n",
       "                                  SVM             0.000000   \n",
       "                         157015   Random Forests  0.000000   \n",
       "                                  SVM             0.000000   \n",
       "            Doctor+Agent No Phase Random Forests  0.000000   \n",
       "                                  SVM             0.000000   \n",
       "                         157015   Random Forests  0.000000   \n",
       "                                  SVM             0.000000   \n",
       "\n",
       "                                                                                             params  \n",
       "Metric      Subject      Phases   Classifier                                                         \n",
       "Presence    Doctor       No Phase Random Forests                                                     \n",
       "                                  SVM                                                                \n",
       "                         157015   Random Forests  {'max_features': 'auto', 'n_estimators': 40, '...  \n",
       "                                  SVM                                                                \n",
       "            Agent        No Phase Random Forests                                                     \n",
       "                                  SVM                                                                \n",
       "                         157015   Random Forests  {'max_features': None, 'n_estimators': 50, 'cl...  \n",
       "                                  SVM                                                                \n",
       "            Doctor+Agent No Phase Random Forests                                                     \n",
       "                                  SVM                                                                \n",
       "                         157015   Random Forests  {'max_features': 'log2', 'n_estimators': 10, '...  \n",
       "                                  SVM                                                                \n",
       "Co-Presence Doctor       No Phase Random Forests                                                     \n",
       "                                  SVM                                                                \n",
       "                         157015   Random Forests                                                     \n",
       "                                  SVM                                                                \n",
       "            Agent        No Phase Random Forests                                                     \n",
       "                                  SVM                                                                \n",
       "                         157015   Random Forests                                                     \n",
       "                                  SVM                                                                \n",
       "            Doctor+Agent No Phase Random Forests                                                     \n",
       "                                  SVM                                                                \n",
       "                         157015   Random Forests                                                     \n",
       "                                  SVM                                                                "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific tests on 'Expert' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific test on expert importance\n",
    "\n",
    "subject_features = (\"Expert\", \"Head_Entropy_Start\", \"Head_Entropy_Mid\", \"Head_Entropy_End\", \"Avg_HandEntropy_Begin\",\n",
    "             \"Avg_HandEntropy_Mid\", \"Avg_HandEntropy_End\", \"Avg_SentenceLength_Begin\", \"Avg_SentenceLength_Mid\",\n",
    "             \"Avg_SentenceLength_End\",  \"Ratio1_Begin\", \"Ratio1_Mid\", \"Ratio1_End\", \"Ratio2_Begin\", \"Ratio2_Mid\", \n",
    "                    \"Ratio2_End\", \"Duration\")\n",
    "\n",
    "subject_noexpert_features = (\"Head_Entropy_Start\", \"Head_Entropy_Mid\", \"Head_Entropy_End\", \"Avg_HandEntropy_Begin\",\n",
    "             \"Avg_HandEntropy_Mid\", \"Avg_HandEntropy_End\", \"Avg_SentenceLength_Begin\", \"Avg_SentenceLength_Mid\",\n",
    "             \"Avg_SentenceLength_End\",  \"Ratio1_Begin\", \"Ratio1_Mid\", \"Ratio1_End\", \"Ratio2_Begin\", \"Ratio2_Mid\", \n",
    "                    \"Ratio2_End\", \"Duration\")\n",
    "\n",
    "# not using \"Expert\" feature for agent features\n",
    "agent_features = (\"Head_Entropy_Start\", \"Head_Entropy_Mid\", \"Head_Entropy_End\", \"Avg_HandEntropy_Begin\",\n",
    "             \"Avg_HandEntropy_Mid\", \"Avg_HandEntropy_End\", \"Avg_SentenceLength_Begin\", \"Avg_SentenceLength_Mid\",\n",
    "             \"Avg_SentenceLength_End\",  \"Ratio1_Begin\", \"Ratio1_Mid\", \"Ratio1_End\", \"Ratio2_Begin\", \"Ratio2_Mid\", \n",
    "                    \"Ratio2_End\", \"Duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 84 candidates, totalling 840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 840 out of 840 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2, 83), indices imply (1, 83)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-753f68ec8ab0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbest_precision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_test_precision_macro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_best_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_precision_macro'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbest_precision\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_best_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_best_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Doctor / Expert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_best_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                 mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[1;32m--> 424\u001b[1;33m                                    copy=copy)\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\internals\\construction.pyc\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\internals\\managers.pyc\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1658\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'values'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1660\u001b[1;33m         \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\internals\\managers.pyc\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[1;32m-> 1691\u001b[1;33m         passed, implied))\n\u001b[0m\u001b[0;32m   1692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (2, 83), indices imply (1, 83)"
     ]
    }
   ],
   "source": [
    "grid1 = gridsearch(forest, subject_p_df, 'presence', param_grid=param_grid, features=subject_features, upsample=True)\n",
    "df = pd.DataFrame(grid1.cv_results_)\n",
    "best_precision = df.mean_test_precision_macro.max()\n",
    "df_best_1 = pd.DataFrame(df.loc[df['mean_test_precision_macro'] == best_precision])\n",
    "df_best_val1 = df_best_1.iloc[0]\n",
    "df_best_1 = pd.DataFrame(df_best_val1.values, columns=['Doctor / Expert'], index=df_best_1.columns).T\n",
    "df_best_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 84 candidates, totalling 840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 840 out of 840 | elapsed:  5.1min finished\n"
     ]
    }
   ],
   "source": [
    "grid2 = gridsearch(forest, subject_p_df, 'presence', param_grid=param_grid, features=subject_noexpert_features, upsample=True)\n",
    "df = pd.DataFrame(grid2.cv_results_)\n",
    "best_precision = df.mean_test_precision_macro.max()\n",
    "df_best_ = pd.DataFrame(df.loc[df['mean_test_precision_macro'] == best_precision])\n",
    "df_best_val2 = df_best_2.iloc[0]\n",
    "df_best_2 = pd.DataFrame(df_best_val2.values, columns=['Doctor / No Expert'], index=df_best_2.columns).T\n",
    "df_best_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 84 candidates, totalling 840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 840 out of 840 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (6, 83), indices imply (1, 83)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-0f8601bcc1f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbest_precision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_test_precision_macro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_best_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_precision_macro'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbest_precision\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_best_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_best_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Agent / No Expert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_best_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                 mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[1;32m--> 424\u001b[1;33m                                    copy=copy)\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\internals\\construction.pyc\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\internals\\managers.pyc\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1658\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'values'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1660\u001b[1;33m         \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\internals\\managers.pyc\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[1;32m-> 1691\u001b[1;33m         passed, implied))\n\u001b[0m\u001b[0;32m   1692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (6, 83), indices imply (1, 83)"
     ]
    }
   ],
   "source": [
    "grid3 = gridsearch(forest, agent_p_df, 'presence', param_grid=param_grid, features=agent_features, upsample=True)\n",
    "df = pd.DataFrame(grid3.cv_results_)\n",
    "best_precision = df.mean_test_precision_macro.max()\n",
    "df_best_3 = pd.DataFrame(df.loc[df['mean_test_precision_macro'] == best_precision])\n",
    "df_best_val3 = df_best_3.iloc[0]\n",
    "df_best_3 = pd.DataFrame(df_best_val3.values, columns=['Agent / No Expert'], index=df_best_3.columns).T\n",
    "df_best_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>mean_test_precision_macro</th>\n",
       "      <th>mean_test_recall_macro</th>\n",
       "      <th>mean_train_f1_macro</th>\n",
       "      <th>mean_train_precision_macro</th>\n",
       "      <th>mean_train_recall_macro</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>...</th>\n",
       "      <th>split9_train_precision_macro</th>\n",
       "      <th>split9_train_recall_macro</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>std_test_precision_macro</th>\n",
       "      <th>std_test_recall_macro</th>\n",
       "      <th>std_train_f1_macro</th>\n",
       "      <th>std_train_precision_macro</th>\n",
       "      <th>std_train_recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Agent / No Expert</th>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.00369997</td>\n",
       "      <td>0.773156</td>\n",
       "      <td>0.831852</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00418211</td>\n",
       "      <td>0.00414847</td>\n",
       "      <td>0.118873</td>\n",
       "      <td>0.0914799</td>\n",
       "      <td>0.11225</td>\n",
       "      <td>0.00430219</td>\n",
       "      <td>0.00416667</td>\n",
       "      <td>0.00430108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean_fit_time mean_score_time mean_test_f1_macro  \\\n",
       "Agent / No Expert        0.0141      0.00369997           0.773156   \n",
       "\n",
       "                  mean_test_precision_macro mean_test_recall_macro  \\\n",
       "Agent / No Expert                  0.831852               0.780952   \n",
       "\n",
       "                  mean_train_f1_macro mean_train_precision_macro  \\\n",
       "Agent / No Expert            0.997849                   0.997917   \n",
       "\n",
       "                  mean_train_recall_macro param_class_weight  \\\n",
       "Agent / No Expert                0.997849               None   \n",
       "\n",
       "                  param_max_features  ... split9_train_precision_macro  \\\n",
       "Agent / No Expert               auto  ...                            1   \n",
       "\n",
       "                  split9_train_recall_macro std_fit_time std_score_time  \\\n",
       "Agent / No Expert                         1   0.00418211     0.00414847   \n",
       "\n",
       "                  std_test_f1_macro std_test_precision_macro  \\\n",
       "Agent / No Expert          0.118873                0.0914799   \n",
       "\n",
       "                  std_test_recall_macro std_train_f1_macro  \\\n",
       "Agent / No Expert               0.11225         0.00430219   \n",
       "\n",
       "                  std_train_precision_macro std_train_recall_macro  \n",
       "Agent / No Expert                0.00416667             0.00430108  \n",
       "\n",
       "[1 rows x 83 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(grid3.cv_results_)\n",
    "best_precision = df.mean_test_precision_macro.max()\n",
    "df_best_3 = pd.DataFrame(df.loc[df['mean_test_precision_macro'] == best_precision])\n",
    "df_best_val3 = df_best_3.iloc[0]\n",
    "df_best_3 = pd.DataFrame(df_best_val3.values, columns=['Agent / No Expert'], index=df_best_3.columns).T\n",
    "df_best_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_precision_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>mean_test_recall_macro</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doctor / Expert</th>\n",
       "      <td>0.814921</td>\n",
       "      <td>0.746969</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>{u'max_features': None, u'n_estimators': 50, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor / No Expert</th>\n",
       "      <td>0.836531</td>\n",
       "      <td>0.793405</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{u'max_features': None, u'n_estimators': 100, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agent / No Expert</th>\n",
       "      <td>0.831852</td>\n",
       "      <td>0.773156</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>{u'max_features': u'auto', u'n_estimators': 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean_test_precision_macro mean_test_f1_macro  \\\n",
       "Doctor / Expert                     0.814921           0.746969   \n",
       "Doctor / No Expert                  0.836531           0.793405   \n",
       "Agent / No Expert                   0.831852           0.773156   \n",
       "\n",
       "                   mean_test_recall_macro  \\\n",
       "Doctor / Expert                  0.761905   \n",
       "Doctor / No Expert                    0.8   \n",
       "Agent / No Expert                0.780952   \n",
       "\n",
       "                                                               params  \n",
       "Doctor / Expert     {u'max_features': None, u'n_estimators': 50, u...  \n",
       "Doctor / No Expert  {u'max_features': None, u'n_estimators': 100, ...  \n",
       "Agent / No Expert   {u'max_features': u'auto', u'n_estimators': 10...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_all = pd.concat([df_best_1, df_best_2, df_best_3])\n",
    "df_best_all[['mean_test_precision_macro', 'mean_test_f1_macro', 'mean_test_recall_macro', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>std_test_precision_macro</th>\n",
       "      <th>std_test_recall_macro</th>\n",
       "      <th>std_train_f1_macro</th>\n",
       "      <th>std_train_precision_macro</th>\n",
       "      <th>std_train_recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.132134</td>\n",
       "      <td>0.165828</td>\n",
       "      <td>0.121312</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.004826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.133546</td>\n",
       "      <td>0.166498</td>\n",
       "      <td>0.118634</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034886</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.143855</td>\n",
       "      <td>0.179382</td>\n",
       "      <td>0.125628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007099</td>\n",
       "      <td>0.004826</td>\n",
       "      <td>0.115380</td>\n",
       "      <td>0.097104</td>\n",
       "      <td>0.114120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005590</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.109027</td>\n",
       "      <td>0.079613</td>\n",
       "      <td>0.109971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.130162</td>\n",
       "      <td>0.124520</td>\n",
       "      <td>0.121187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.035410</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.133596</td>\n",
       "      <td>0.128389</td>\n",
       "      <td>0.123044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.084147</td>\n",
       "      <td>0.073661</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.110407</td>\n",
       "      <td>0.116601</td>\n",
       "      <td>0.101872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>0.126775</td>\n",
       "      <td>0.116220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004468</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.110440</td>\n",
       "      <td>0.090709</td>\n",
       "      <td>0.112955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.136320</td>\n",
       "      <td>0.132022</td>\n",
       "      <td>0.128806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.145617</td>\n",
       "      <td>0.138653</td>\n",
       "      <td>0.136582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.028111</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>0.125663</td>\n",
       "      <td>0.128901</td>\n",
       "      <td>0.112754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.084147</td>\n",
       "      <td>0.073661</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.003382</td>\n",
       "      <td>0.110407</td>\n",
       "      <td>0.116601</td>\n",
       "      <td>0.101872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>0.126775</td>\n",
       "      <td>0.116220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006848</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.110440</td>\n",
       "      <td>0.090709</td>\n",
       "      <td>0.112955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.004928</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.136320</td>\n",
       "      <td>0.132022</td>\n",
       "      <td>0.128806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.013497</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.145617</td>\n",
       "      <td>0.138653</td>\n",
       "      <td>0.136582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.062058</td>\n",
       "      <td>0.019393</td>\n",
       "      <td>0.125663</td>\n",
       "      <td>0.128901</td>\n",
       "      <td>0.112754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.084147</td>\n",
       "      <td>0.073661</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.110407</td>\n",
       "      <td>0.116601</td>\n",
       "      <td>0.101872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>0.126775</td>\n",
       "      <td>0.116220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005108</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.110440</td>\n",
       "      <td>0.090709</td>\n",
       "      <td>0.112955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.136320</td>\n",
       "      <td>0.132022</td>\n",
       "      <td>0.128806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.145617</td>\n",
       "      <td>0.138653</td>\n",
       "      <td>0.136582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.057628</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>0.125663</td>\n",
       "      <td>0.128901</td>\n",
       "      <td>0.112754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.132134</td>\n",
       "      <td>0.165828</td>\n",
       "      <td>0.121312</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.004826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.133546</td>\n",
       "      <td>0.166498</td>\n",
       "      <td>0.118634</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.013589</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.145617</td>\n",
       "      <td>0.138653</td>\n",
       "      <td>0.136582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.101283</td>\n",
       "      <td>0.016242</td>\n",
       "      <td>0.125663</td>\n",
       "      <td>0.128901</td>\n",
       "      <td>0.112754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.003544</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.167014</td>\n",
       "      <td>0.210353</td>\n",
       "      <td>0.161554</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>0.005214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.120550</td>\n",
       "      <td>0.176845</td>\n",
       "      <td>0.102427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>0.104046</td>\n",
       "      <td>0.135741</td>\n",
       "      <td>0.098285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.017304</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>0.107917</td>\n",
       "      <td>0.135997</td>\n",
       "      <td>0.099507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.016117</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.105020</td>\n",
       "      <td>0.117366</td>\n",
       "      <td>0.099507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.019586</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.141573</td>\n",
       "      <td>0.151115</td>\n",
       "      <td>0.128806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.040515</td>\n",
       "      <td>0.028023</td>\n",
       "      <td>0.136354</td>\n",
       "      <td>0.148026</td>\n",
       "      <td>0.123044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.117917</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.108135</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.006297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.006450</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.112843</td>\n",
       "      <td>0.097814</td>\n",
       "      <td>0.113189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.006344</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.123512</td>\n",
       "      <td>0.102862</td>\n",
       "      <td>0.124419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.006034</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.129254</td>\n",
       "      <td>0.111541</td>\n",
       "      <td>0.128806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.133994</td>\n",
       "      <td>0.127645</td>\n",
       "      <td>0.124419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.005546</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.146913</td>\n",
       "      <td>0.142563</td>\n",
       "      <td>0.137657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.233796</td>\n",
       "      <td>0.029742</td>\n",
       "      <td>0.124730</td>\n",
       "      <td>0.125555</td>\n",
       "      <td>0.112250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.117917</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.108135</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.006297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.112843</td>\n",
       "      <td>0.097814</td>\n",
       "      <td>0.113189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.123512</td>\n",
       "      <td>0.102862</td>\n",
       "      <td>0.124419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.129254</td>\n",
       "      <td>0.111541</td>\n",
       "      <td>0.128806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.133994</td>\n",
       "      <td>0.127645</td>\n",
       "      <td>0.124419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.146913</td>\n",
       "      <td>0.142563</td>\n",
       "      <td>0.137657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.085941</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>0.124730</td>\n",
       "      <td>0.125555</td>\n",
       "      <td>0.112250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.117917</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.108135</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.006297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.112843</td>\n",
       "      <td>0.097814</td>\n",
       "      <td>0.113189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.023804</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.123512</td>\n",
       "      <td>0.102862</td>\n",
       "      <td>0.124419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.036610</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.129254</td>\n",
       "      <td>0.111541</td>\n",
       "      <td>0.128806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.006290</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.133994</td>\n",
       "      <td>0.127645</td>\n",
       "      <td>0.124419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.014662</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.146913</td>\n",
       "      <td>0.142563</td>\n",
       "      <td>0.137657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.376260</td>\n",
       "      <td>0.025965</td>\n",
       "      <td>0.124730</td>\n",
       "      <td>0.125555</td>\n",
       "      <td>0.112250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    std_fit_time  std_score_time  std_test_f1_macro  std_test_precision_macro  \\\n",
       "0       0.002871        0.002256           0.132134                  0.165828   \n",
       "1       0.003661        0.001814           0.133546                  0.166498   \n",
       "2       0.034886        0.003231           0.143855                  0.179382   \n",
       "3       0.007099        0.004826           0.115380                  0.097104   \n",
       "4       0.005590        0.002193           0.109027                  0.079613   \n",
       "5       0.008237        0.003716           0.130162                  0.124520   \n",
       "6       0.035410        0.018779           0.133596                  0.128389   \n",
       "7       0.003807        0.003873           0.084147                  0.073661   \n",
       "8       0.008453        0.002764           0.110407                  0.116601   \n",
       "9       0.009600        0.004331           0.117534                  0.126775   \n",
       "10      0.004468        0.001908           0.110440                  0.090709   \n",
       "11      0.005800        0.003807           0.136320                  0.132022   \n",
       "12      0.009456        0.001911           0.145617                  0.138653   \n",
       "13      0.028111        0.015740           0.125663                  0.128901   \n",
       "14      0.004605        0.004069           0.084147                  0.073661   \n",
       "15      0.004206        0.003382           0.110407                  0.116601   \n",
       "16      0.004454        0.003208           0.117534                  0.126775   \n",
       "17      0.006848        0.002579           0.110440                  0.090709   \n",
       "18      0.004928        0.003002           0.136320                  0.132022   \n",
       "19      0.013497        0.004792           0.145617                  0.138653   \n",
       "20      0.062058        0.019393           0.125663                  0.128901   \n",
       "21      0.004253        0.003499           0.084147                  0.073661   \n",
       "22      0.005143        0.003905           0.110407                  0.116601   \n",
       "23      0.003341        0.003429           0.117534                  0.126775   \n",
       "24      0.005108        0.002655           0.110440                  0.090709   \n",
       "25      0.005693        0.003066           0.136320                  0.132022   \n",
       "26      0.008075        0.001900           0.145617                  0.138653   \n",
       "27      0.057628        0.012464           0.125663                  0.128901   \n",
       "28      0.002532        0.002586           0.132134                  0.165828   \n",
       "29      0.002800        0.003555           0.133546                  0.166498   \n",
       "..           ...             ...                ...                       ...   \n",
       "54      0.013589        0.003736           0.145617                  0.138653   \n",
       "55      0.101283        0.016242           0.125663                  0.128901   \n",
       "56      0.003544        0.003768           0.167014                  0.210353   \n",
       "57      0.004674        0.003600           0.120550                  0.176845   \n",
       "58      0.003910        0.005381           0.104046                  0.135741   \n",
       "59      0.017304        0.005065           0.107917                  0.135997   \n",
       "60      0.016117        0.004477           0.105020                  0.117366   \n",
       "61      0.019586        0.004406           0.141573                  0.151115   \n",
       "62      0.040515        0.028023           0.136354                  0.148026   \n",
       "63      0.004750        0.002191           0.117917                  0.126316   \n",
       "64      0.006450        0.003931           0.112843                  0.097814   \n",
       "65      0.006344        0.003487           0.123512                  0.102862   \n",
       "66      0.006034        0.002532           0.129254                  0.111541   \n",
       "67      0.014127        0.002166           0.133994                  0.127645   \n",
       "68      0.005546        0.002685           0.146913                  0.142563   \n",
       "69      0.233796        0.029742           0.124730                  0.125555   \n",
       "70      0.002993        0.002600           0.117917                  0.126316   \n",
       "71      0.003040        0.002926           0.112843                  0.097814   \n",
       "72      0.003194        0.002490           0.123512                  0.102862   \n",
       "73      0.004584        0.003100           0.129254                  0.111541   \n",
       "74      0.010538        0.002377           0.133994                  0.127645   \n",
       "75      0.004964        0.003227           0.146913                  0.142563   \n",
       "76      0.085941        0.012330           0.124730                  0.125555   \n",
       "77      0.004863        0.004578           0.117917                  0.126316   \n",
       "78      0.002366        0.003780           0.112843                  0.097814   \n",
       "79      0.023804        0.007975           0.123512                  0.102862   \n",
       "80      0.036610        0.003370           0.129254                  0.111541   \n",
       "81      0.006290        0.002655           0.133994                  0.127645   \n",
       "82      0.014662        0.003557           0.146913                  0.142563   \n",
       "83      0.376260        0.025965           0.124730                  0.125555   \n",
       "\n",
       "    std_test_recall_macro  std_train_f1_macro  std_train_precision_macro  \\\n",
       "0                0.121312            0.004827                   0.004678   \n",
       "1                0.118634            0.003126                   0.003030   \n",
       "2                0.125628            0.000000                   0.000000   \n",
       "3                0.114120            0.000000                   0.000000   \n",
       "4                0.109971            0.000000                   0.000000   \n",
       "5                0.121187            0.000000                   0.000000   \n",
       "6                0.123044            0.000000                   0.000000   \n",
       "7                0.088363            0.004168                   0.004040   \n",
       "8                0.101872            0.000000                   0.000000   \n",
       "9                0.116220            0.000000                   0.000000   \n",
       "10               0.112955            0.000000                   0.000000   \n",
       "11               0.128806            0.000000                   0.000000   \n",
       "12               0.136582            0.000000                   0.000000   \n",
       "13               0.112754            0.000000                   0.000000   \n",
       "14               0.088363            0.004168                   0.004040   \n",
       "15               0.101872            0.000000                   0.000000   \n",
       "16               0.116220            0.000000                   0.000000   \n",
       "17               0.112955            0.000000                   0.000000   \n",
       "18               0.128806            0.000000                   0.000000   \n",
       "19               0.136582            0.000000                   0.000000   \n",
       "20               0.112754            0.000000                   0.000000   \n",
       "21               0.088363            0.004168                   0.004040   \n",
       "22               0.101872            0.000000                   0.000000   \n",
       "23               0.116220            0.000000                   0.000000   \n",
       "24               0.112955            0.000000                   0.000000   \n",
       "25               0.128806            0.000000                   0.000000   \n",
       "26               0.136582            0.000000                   0.000000   \n",
       "27               0.112754            0.000000                   0.000000   \n",
       "28               0.121312            0.004827                   0.004678   \n",
       "29               0.118634            0.003126                   0.003030   \n",
       "..                    ...                 ...                        ...   \n",
       "54               0.136582            0.000000                   0.000000   \n",
       "55               0.112754            0.000000                   0.000000   \n",
       "56               0.161554            0.005216                   0.005053   \n",
       "57               0.102427            0.000000                   0.000000   \n",
       "58               0.098285            0.000000                   0.000000   \n",
       "59               0.099507            0.000000                   0.000000   \n",
       "60               0.099507            0.000000                   0.000000   \n",
       "61               0.128806            0.000000                   0.000000   \n",
       "62               0.123044            0.000000                   0.000000   \n",
       "63               0.108135            0.006298                   0.006167   \n",
       "64               0.113189            0.000000                   0.000000   \n",
       "65               0.124419            0.000000                   0.000000   \n",
       "66               0.128806            0.000000                   0.000000   \n",
       "67               0.124419            0.000000                   0.000000   \n",
       "68               0.137657            0.000000                   0.000000   \n",
       "69               0.112250            0.000000                   0.000000   \n",
       "70               0.108135            0.006298                   0.006167   \n",
       "71               0.113189            0.000000                   0.000000   \n",
       "72               0.124419            0.000000                   0.000000   \n",
       "73               0.128806            0.000000                   0.000000   \n",
       "74               0.124419            0.000000                   0.000000   \n",
       "75               0.137657            0.000000                   0.000000   \n",
       "76               0.112250            0.000000                   0.000000   \n",
       "77               0.108135            0.006298                   0.006167   \n",
       "78               0.113189            0.000000                   0.000000   \n",
       "79               0.124419            0.000000                   0.000000   \n",
       "80               0.128806            0.000000                   0.000000   \n",
       "81               0.124419            0.000000                   0.000000   \n",
       "82               0.137657            0.000000                   0.000000   \n",
       "83               0.112250            0.000000                   0.000000   \n",
       "\n",
       "    std_train_recall_macro  \n",
       "0                 0.004826  \n",
       "1                 0.003125  \n",
       "2                 0.000000  \n",
       "3                 0.000000  \n",
       "4                 0.000000  \n",
       "5                 0.000000  \n",
       "6                 0.000000  \n",
       "7                 0.004167  \n",
       "8                 0.000000  \n",
       "9                 0.000000  \n",
       "10                0.000000  \n",
       "11                0.000000  \n",
       "12                0.000000  \n",
       "13                0.000000  \n",
       "14                0.004167  \n",
       "15                0.000000  \n",
       "16                0.000000  \n",
       "17                0.000000  \n",
       "18                0.000000  \n",
       "19                0.000000  \n",
       "20                0.000000  \n",
       "21                0.004167  \n",
       "22                0.000000  \n",
       "23                0.000000  \n",
       "24                0.000000  \n",
       "25                0.000000  \n",
       "26                0.000000  \n",
       "27                0.000000  \n",
       "28                0.004826  \n",
       "29                0.003125  \n",
       "..                     ...  \n",
       "54                0.000000  \n",
       "55                0.000000  \n",
       "56                0.005214  \n",
       "57                0.000000  \n",
       "58                0.000000  \n",
       "59                0.000000  \n",
       "60                0.000000  \n",
       "61                0.000000  \n",
       "62                0.000000  \n",
       "63                0.006297  \n",
       "64                0.000000  \n",
       "65                0.000000  \n",
       "66                0.000000  \n",
       "67                0.000000  \n",
       "68                0.000000  \n",
       "69                0.000000  \n",
       "70                0.006297  \n",
       "71                0.000000  \n",
       "72                0.000000  \n",
       "73                0.000000  \n",
       "74                0.000000  \n",
       "75                0.000000  \n",
       "76                0.000000  \n",
       "77                0.006297  \n",
       "78                0.000000  \n",
       "79                0.000000  \n",
       "80                0.000000  \n",
       "81                0.000000  \n",
       "82                0.000000  \n",
       "83                0.000000  \n",
       "\n",
       "[84 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(grid1.cv_results_)\n",
    "cols = [col for col in df.columns if 'std' in col]\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-197-25cf265ae80d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mplot_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Doctor / Expert'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubject_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mplot_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Doctor / No expert'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubject_noexpert_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mplot_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Agent / No expert'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid1' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_importance(title, importances, importances_err, feature_names, sort=True):\n",
    "    # Sort feature importances in descending order\n",
    "    if sort:\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "    else:\n",
    "        indices = np.arange(len(feature_names))\n",
    "\n",
    "    # Rearrange feature names so they match the sorted feature importances\n",
    "    names = [feature_names[i] for i in indices]\n",
    "    if importances_err is not None:\n",
    "        errs = [importances_err[i] for i in indices]\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure()\n",
    "\n",
    "    # Create plot title\n",
    "    plt.title(\"Feature Importance - \" + title)\n",
    "\n",
    "    # Add bars\n",
    "    if importances_err is not None:\n",
    "        plt.bar(range(len(feature_names)), importances[indices], yerr=errs, xerr=0.1)\n",
    "    else:\n",
    "        plt.bar(range(len(feature_names)), importances[indices])\n",
    "\n",
    "    # Add feature names as x-axis labels\n",
    "    plt.xticks(range(len(feature_names)), names, rotation=90)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    \n",
    "plot_importance('Doctor / Expert', grid1.best_estimator_.feature_importances_, None, subject_features, sort=False)\n",
    "plot_importance('Doctor / No expert', grid2.best_estimator_.feature_importances_, None, subject_noexpert_features, sort=False)\n",
    "plot_importance('Agent / No expert', grid3.best_estimator_.feature_importances_, None, agent_features, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8866952590268444, 1.1047333124017271)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "def confint(a):\n",
    "    return st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))\n",
    "\n",
    "a = [1, 1.1, 0.9, 1.15, 0.8, 1.03, 0.99]\n",
    "print(confint(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.index = rdf.index.swaplevel(2,3)\n",
    "rdf.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Phases</th>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Random Forests</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">Co-Presence</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">157015</th>\n",
       "      <th>Agent</th>\n",
       "      <td>0.857977</td>\n",
       "      <td>0.843006</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 40, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>0.843895</td>\n",
       "      <td>0.775644</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 10, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor+Agent</th>\n",
       "      <td>0.891758</td>\n",
       "      <td>0.857478</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 100, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">No Phase</th>\n",
       "      <th>Agent</th>\n",
       "      <td>0.916809</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 30, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>0.821652</td>\n",
       "      <td>0.798101</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 30, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor+Agent</th>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.827934</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 10, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Presence</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">157015</th>\n",
       "      <th>Agent</th>\n",
       "      <td>0.810794</td>\n",
       "      <td>0.754127</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 20, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>0.778753</td>\n",
       "      <td>0.723586</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 40, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor+Agent</th>\n",
       "      <td>0.782381</td>\n",
       "      <td>0.747407</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 50, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">No Phase</th>\n",
       "      <th>Agent</th>\n",
       "      <td>0.763946</td>\n",
       "      <td>0.733961</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 30, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>0.816032</td>\n",
       "      <td>0.776039</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 50, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor+Agent</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.808904</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>{'max_features': None, 'n_estimators': 40, 'cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">SVM</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">Co-Presence</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">157015</th>\n",
       "      <th>Agent</th>\n",
       "      <td>0.919678</td>\n",
       "      <td>0.882360</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.855305</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor+Agent</th>\n",
       "      <td>0.891209</td>\n",
       "      <td>0.858275</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">No Phase</th>\n",
       "      <th>Agent</th>\n",
       "      <td>0.920391</td>\n",
       "      <td>0.870184</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>0.897212</td>\n",
       "      <td>0.821709</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor+Agent</th>\n",
       "      <td>0.890761</td>\n",
       "      <td>0.862064</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Presence</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">157015</th>\n",
       "      <th>Agent</th>\n",
       "      <td>0.883039</td>\n",
       "      <td>0.793964</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>0.927302</td>\n",
       "      <td>0.892880</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor+Agent</th>\n",
       "      <td>0.913515</td>\n",
       "      <td>0.862339</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">No Phase</th>\n",
       "      <th>Agent</th>\n",
       "      <td>0.818995</td>\n",
       "      <td>0.784713</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>0.843900</td>\n",
       "      <td>0.801139</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor+Agent</th>\n",
       "      <td>0.898753</td>\n",
       "      <td>0.843911</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  precision        f1  \\\n",
       "Classifier     Metric      Phases   Subject                             \n",
       "Random Forests Co-Presence 157015   Agent          0.857977  0.843006   \n",
       "                                    Doctor         0.843895  0.775644   \n",
       "                                    Doctor+Agent   0.891758  0.857478   \n",
       "                           No Phase Agent          0.916809  0.893617   \n",
       "                                    Doctor         0.821652  0.798101   \n",
       "                                    Doctor+Agent   0.868091  0.827934   \n",
       "               Presence    157015   Agent          0.810794  0.754127   \n",
       "                                    Doctor         0.778753  0.723586   \n",
       "                                    Doctor+Agent   0.782381  0.747407   \n",
       "                           No Phase Agent          0.763946  0.733961   \n",
       "                                    Doctor         0.816032  0.776039   \n",
       "                                    Doctor+Agent   0.844444  0.808904   \n",
       "SVM            Co-Presence 157015   Agent          0.919678  0.882360   \n",
       "                                    Doctor         0.881481  0.855305   \n",
       "                                    Doctor+Agent   0.891209  0.858275   \n",
       "                           No Phase Agent          0.920391  0.870184   \n",
       "                                    Doctor         0.897212  0.821709   \n",
       "                                    Doctor+Agent   0.890761  0.862064   \n",
       "               Presence    157015   Agent          0.883039  0.793964   \n",
       "                                    Doctor         0.927302  0.892880   \n",
       "                                    Doctor+Agent   0.913515  0.862339   \n",
       "                           No Phase Agent          0.818995  0.784713   \n",
       "                                    Doctor         0.843900  0.801139   \n",
       "                                    Doctor+Agent   0.898753  0.843911   \n",
       "\n",
       "                                                    recall  \\\n",
       "Classifier     Metric      Phases   Subject                  \n",
       "Random Forests Co-Presence 157015   Agent         0.846154   \n",
       "                                    Doctor        0.794872   \n",
       "                                    Doctor+Agent  0.863248   \n",
       "                           No Phase Agent         0.897436   \n",
       "                                    Doctor        0.803419   \n",
       "                                    Doctor+Agent  0.837607   \n",
       "               Presence    157015   Agent         0.771429   \n",
       "                                    Doctor        0.742857   \n",
       "                                    Doctor+Agent  0.752381   \n",
       "                           No Phase Agent         0.742857   \n",
       "                                    Doctor        0.780952   \n",
       "                                    Doctor+Agent  0.819048   \n",
       "SVM            Co-Presence 157015   Agent         0.888889   \n",
       "                                    Doctor        0.871795   \n",
       "                                    Doctor+Agent  0.871795   \n",
       "                           No Phase Agent         0.880342   \n",
       "                                    Doctor        0.837607   \n",
       "                                    Doctor+Agent  0.880342   \n",
       "               Presence    157015   Agent         0.800000   \n",
       "                                    Doctor        0.895238   \n",
       "                                    Doctor+Agent  0.866667   \n",
       "                           No Phase Agent         0.809524   \n",
       "                                    Doctor        0.809524   \n",
       "                                    Doctor+Agent  0.847619   \n",
       "\n",
       "                                                                                             params  \n",
       "Classifier     Metric      Phases   Subject                                                          \n",
       "Random Forests Co-Presence 157015   Agent         {'max_features': None, 'n_estimators': 40, 'cl...  \n",
       "                                    Doctor        {'max_features': None, 'n_estimators': 10, 'cl...  \n",
       "                                    Doctor+Agent  {'max_features': 'auto', 'n_estimators': 100, ...  \n",
       "                           No Phase Agent         {'max_features': 'auto', 'n_estimators': 30, '...  \n",
       "                                    Doctor        {'max_features': 'auto', 'n_estimators': 30, '...  \n",
       "                                    Doctor+Agent  {'max_features': 'auto', 'n_estimators': 10, '...  \n",
       "               Presence    157015   Agent         {'max_features': None, 'n_estimators': 20, 'cl...  \n",
       "                                    Doctor        {'max_features': 'auto', 'n_estimators': 40, '...  \n",
       "                                    Doctor+Agent  {'max_features': 'auto', 'n_estimators': 50, '...  \n",
       "                           No Phase Agent         {'max_features': None, 'n_estimators': 30, 'cl...  \n",
       "                                    Doctor        {'max_features': 'auto', 'n_estimators': 50, '...  \n",
       "                                    Doctor+Agent  {'max_features': None, 'n_estimators': 40, 'cl...  \n",
       "SVM            Co-Presence 157015   Agent                 {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}  \n",
       "                                    Doctor                {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}  \n",
       "                                    Doctor+Agent          {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}  \n",
       "                           No Phase Agent                 {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}  \n",
       "                                    Doctor                {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}  \n",
       "                                    Doctor+Agent          {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}  \n",
       "               Presence    157015   Agent                 {'kernel': 'rbf', 'C': 1.0, 'gamma': 1.0}  \n",
       "                                    Doctor                {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}  \n",
       "                                    Doctor+Agent          {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}  \n",
       "                           No Phase Agent                {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}  \n",
       "                                    Doctor               {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}  \n",
       "                                    Doctor+Agent          {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features importance experiments\n",
    "\n",
    "We would like to check variance and quality of this estimator.\n",
    "For this we first experiment cross validations with searching also n_estimators, or fixing it with a high value, and check if and how best parameters vary.\n",
    "Then we will check for a specific set of params, how results and feature importance vary upon repeated runs.\n",
    "Depending on results, we will compute feature importance for all test plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rfpimp - not compatible with python 2 ?\n",
    "\n",
    "from sklearn.ensemble.forest import _generate_unsampled_indices\n",
    "\n",
    "\n",
    "def oob_classifier_accuracy(rf, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Compute out-of-bag (OOB) accuracy for a scikit-learn random forest\n",
    "    classifier. We learned the guts of scikit's RF from the BSD licensed\n",
    "    code:\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/ensemble/forest.py#L425\n",
    "    \"\"\"\n",
    "\n",
    "    X = X_train.values\n",
    "    y = y_train.values\n",
    "\n",
    "    n_samples = len(X)\n",
    "    n_classes = len(np.unique(y))\n",
    "    predictions = np.zeros((n_samples, n_classes))\n",
    "\n",
    "    for tree in rf.estimators_:\n",
    "        unsampled_indices = _generate_unsampled_indices(tree.random_state, n_samples)\n",
    "        tree_preds = tree.predict_proba(X[unsampled_indices, :])\n",
    "        predictions[unsampled_indices] += tree_preds\n",
    "\n",
    "    predicted_class_indexes = np.argmax(predictions, axis=1)\n",
    "    predicted_classes = [rf.classes_[i] for i in predicted_class_indexes]\n",
    "    oob_score = np.mean(y == predicted_classes)\n",
    "\n",
    "    return oob_score\n",
    "\n",
    "def dropcol_importances(model, X_train, y_train, X_valid=None, y_valid=None, metric=None, sample_weights=None):\n",
    "    \"\"\"\n",
    "    Compute drop-column feature importances for scikit-learn.\n",
    "\n",
    "    Given a classifier or regression in model\n",
    "    and training X and y data, return a data frame with columns\n",
    "    Feature and Importance sorted in reverse order by importance.\n",
    "\n",
    "    A clone of model is trained once to get the baseline score and then\n",
    "    again, once per feature to compute the drop in either the model's .score() output\n",
    "    or a custom metric callable in the form of metric(model, X_valid, y_valid).\n",
    "    In case of a custom metric the X_valid and y_valid parameters should be set.\n",
    "    return: A data frame with Feature, Importance columns\n",
    "\n",
    "    SAMPLE CODE\n",
    "    rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "    X_train, y_train = ..., ...\n",
    "    rf.fit(X_train, y_train)\n",
    "    imp = dropcol_importances(rf, X_train, y_train)\n",
    "    \"\"\"\n",
    "\n",
    "    if X_valid is None: X_valid = X_train\n",
    "    if y_valid is None: y_valid = y_train\n",
    "    model_ = clone(model)\n",
    "    model_.random_state = RANDOM_STATE\n",
    "    model_.fit(X_train, y_train)\n",
    "\n",
    "    if callable(metric):\n",
    "        baseline = metric(model_, X_valid, y_valid)\n",
    "    else:\n",
    "        baseline = model_.score(X_valid, y_valid)\n",
    "\n",
    "    imp = []\n",
    "    for col in X_train.columns:\n",
    "        model_ = clone(model)\n",
    "        model_.random_state = RANDOM_STATE\n",
    "        model_.fit(X_train.drop(col,axis=1), y_train)\n",
    "        if callable(metric):\n",
    "            s = metric(model_, X_valid.drop(col,axis=1), y_valid)\n",
    "        else:\n",
    "            s = model_.score(X_valid.drop(col,axis=1), y_valid)\n",
    "        drop_in_score = baseline - s\n",
    "        imp.append(drop_in_score)\n",
    "\n",
    "    imp = np.array(imp)\n",
    "\n",
    "    I = pd.DataFrame(data={'Feature':X_train.columns, 'Importance':imp})\n",
    "    I = I.set_index('Feature')\n",
    "    I = I.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    return I\n",
    "\n",
    "def dropcol_importances(rf, X_train, y_train, random_state):\n",
    "    rf_ = clone(rf)\n",
    "    rf_.random_state = random_state\n",
    "    rf_.fit(X_train, y_train)\n",
    "    baseline = rf_.oob_score_\n",
    "    #print(\"baseline \" + str(baseline))\n",
    "    imp = []\n",
    "    for col in X_train.columns:\n",
    "        X = X_train.drop(col, axis=1)\n",
    "        rf_ = clone(rf)\n",
    "        rf_.random_state = random_state\n",
    "        rf_.fit(X, y_train)\n",
    "        o = rf_.oob_score_\n",
    "        imp.append(baseline - o)\n",
    "    imp = np.array(imp)\n",
    "    #I = pd.DataFrame(\n",
    "    #        data={'Feature':X_train.columns,\n",
    "    #              'Importance':imp})\n",
    "    #I = I.set_index('Feature')\n",
    "    #I = I.sort_values('Importance', ascending=True)\n",
    "    return imp #I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 2, 3], dtype=int64), array([37, 37, 37]))\n",
      "  Gridsearch evaluated best score 0.7525343525343525\n",
      "    Running 10 iterations on best classifier {'max_features': None, 'n_estimators': 30, 'max_depth': None, 'min_samples_leaf': 1} ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "def scoreForest(estimator, X, y):\n",
    "    \"\"\"\n",
    "    Custom scoring function for hyperparameter optimization. In this case, we want to print out the oob score.\n",
    "    estimator was fitted on train data, X and y here are validation data.\n",
    "    For OOB we don't need validation data - OOB is inherent to tree building.\n",
    "    Same for feature importances (with default gini impurity measure done by sklearn).\n",
    "    We add to this the \n",
    "    \"\"\"\n",
    "    all_feature_importances.append(estimator.feature_importances_)\n",
    "    score = estimator.oob_score_\n",
    "    #print \"oob_score_:\", score\n",
    "    return score\n",
    "\n",
    "def run_cross_val_score(clf, X, y, verbose=1):\n",
    "    #print(\"gridsearch(clf=%s, modelTarget=%s, param_grid=%s, features=%s, upsample=%s)\" \n",
    "    #      % (type(clf), modelTarget, param_grid, features, upsample))\n",
    "\n",
    "    scoring = {\n",
    "        'oob' : scoreForest,\n",
    "        'f1_macro' : 'f1_macro',\n",
    "        'f1_macro_class_1': make_scorer(f1_score, labels=[1], average='macro'),\n",
    "        'f1_macro_class_2': make_scorer(f1_score, labels=[2], average='macro'),\n",
    "        'f1_macro_class_3': make_scorer(f1_score, labels=[3], average='macro'),\n",
    "        'precision_macro' : 'precision_macro',\n",
    "        'precision_macro_class_1': make_scorer(precision_score, labels=[1], average='macro'),\n",
    "        'precision_macro_class_2': make_scorer(precision_score, labels=[2], average='macro'),\n",
    "        'precision_macro_class_3': make_scorer(precision_score, labels=[3], average='macro'),\n",
    "        'recall_macro' : 'recall_macro',\n",
    "        'recall_macro_class_1': make_scorer(recall_score, labels=[1], average='macro'),\n",
    "        'recall_macro_class_2': make_scorer(recall_score, labels=[2], average='macro'),\n",
    "        'recall_macro_class_3': make_scorer(recall_score, labels=[3], average='macro')           \n",
    "    }\n",
    "    \n",
    "    return cross_validate(clf, X, y, scoring=scoring, cv=10, return_train_score=False, verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "# random forests\n",
    "param_grid =  {\n",
    "    'n_estimators' : [10, 20, 30, 40, 50, 100, 1000],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "    \"max_depth\": [None, 2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 5, 10]\n",
    "}\n",
    "\n",
    "# n : number of repeated runs performed to compute averages and confidence intervals\n",
    "n = 10\n",
    "\n",
    "def run_gridsearch_with_feature_importances(dataframe, target_model, features_names, upsample=True):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    X, y = prepare_train_data(subject_np_df, 'presence', subject_features_nophase, upsample=True)\n",
    "\n",
    "    # first evaluate best params through grid search for this particular test\n",
    "    grid = gridsearch(forest, \n",
    "                      X, y, \n",
    "                      'presence', \n",
    "                      param_grid=param_grid, \n",
    "                      features=subject_features, \n",
    "                      upsample=True, \n",
    "                      verbose=0)\n",
    "    best_params = grid.best_params_\n",
    "    single_best_score = grid.best_score_\n",
    "\n",
    "    print('  Gridsearch evaluated best score %s' % (single_best_score))\n",
    "    print('    Running %d iterations on best classifier %s ...' % (n, best_params))\n",
    "\n",
    "    all_scores = []\n",
    "    all_feature_importances = []\n",
    "    all_dropcol_feature_importances = []\n",
    "    for i in np.arange(n):\n",
    "        forest = RandomForestClassifier(oob_score=True)\n",
    "        forest.set_params(**best_params)\n",
    "\n",
    "        scores = run_cross_val_score(forest, \n",
    "                          X, y,  \n",
    "                          verbose=0)\n",
    "    #    print(scores)\n",
    "        scores_df = pd.DataFrame(scores)\n",
    "        #print(scores_df)\n",
    "        #print(scores_df.columns)\n",
    "        all_scores.append(scores_df)\n",
    "\n",
    "    X_ = pd.DataFrame(X, columns=subject_features_nophase)\n",
    "    y_ = pd.DataFrame(y)\n",
    "    for i in np.arange(300):\n",
    "        # alternative computation for feature importance\n",
    "        all_dropcol_feature_importances.append(dropcol_importances(forest, X_, y_, RANDOM_STATE+i))\n",
    "\n",
    "    all_scores = pd.concat(all_scores)\n",
    "    all_feature_importances = pd.DataFrame(all_feature_importances, columns=subject_features_nophase)\n",
    "    all_dropcol_features_importances = pd.DataFrame(all_dropcol_feature_importances, columns=subject_features_nophase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "def scoreForest(estimator, X, y):\n",
    "    \"\"\"\n",
    "    Custom scoring function for hyperparameter optimization. In this case, we want to print out the oob score.\n",
    "    estimator was fitted on train data, X and y here are validation data.\n",
    "    For OOB we don't need validation data - OOB is inherent to tree building.\n",
    "    Same for feature importances (with default gini impurity measure done by sklearn).\n",
    "    We add to this the \n",
    "    \"\"\"\n",
    "    all_feature_importances.append(estimator.feature_importances_)\n",
    "    score = estimator.oob_score_\n",
    "    #print \"oob_score_:\", score\n",
    "    return score\n",
    "\n",
    "def run_cross_val_score(clf, X, y, verbose=1):\n",
    "    #print(\"gridsearch(clf=%s, modelTarget=%s, param_grid=%s, features=%s, upsample=%s)\" \n",
    "    #      % (type(clf), modelTarget, param_grid, features, upsample))\n",
    "\n",
    "    scoring = {\n",
    "        'oob' : scoreForest,\n",
    "        'f1_macro' : 'f1_macro',\n",
    "        'f1_macro_class_1': make_scorer(f1_score, labels=[1], average='macro'),\n",
    "        'f1_macro_class_2': make_scorer(f1_score, labels=[2], average='macro'),\n",
    "        'f1_macro_class_3': make_scorer(f1_score, labels=[3], average='macro'),\n",
    "        'precision_macro' : 'precision_macro',\n",
    "        'precision_macro_class_1': make_scorer(precision_score, labels=[1], average='macro'),\n",
    "        'precision_macro_class_2': make_scorer(precision_score, labels=[2], average='macro'),\n",
    "        'precision_macro_class_3': make_scorer(precision_score, labels=[3], average='macro'),\n",
    "        'recall_macro' : 'recall_macro',\n",
    "        'recall_macro_class_1': make_scorer(recall_score, labels=[1], average='macro'),\n",
    "        'recall_macro_class_2': make_scorer(recall_score, labels=[2], average='macro'),\n",
    "        'recall_macro_class_3': make_scorer(recall_score, labels=[3], average='macro')           \n",
    "    }\n",
    "    \n",
    "    return cross_validate(clf, X, y, scoring=scoring, cv=10, return_train_score=False, verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "# random forests\n",
    "param_grid =  {\n",
    "    'n_estimators' : [10, 20, 30, 40, 50, 100, 1000],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "    \"max_depth\": [None, 2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 5, 10]\n",
    "}\n",
    "\n",
    "# n : number of repeated runs performed to compute averages and confidence intervals\n",
    "n = 10\n",
    "\n",
    "def run_gridsearch_with_feature_importances(clf, dataframe, target_model, features_names, upsample=True):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    X, y = prepare_train_data(dataframe, target_model, features_names, upsample=True)\n",
    "\n",
    "    # first evaluate best params through grid search for this particular test\n",
    "    grid = gridsearch(clf, \n",
    "                      X, y, \n",
    "                      'presence', \n",
    "                      param_grid=param_grid, \n",
    "                      features=subject_features, \n",
    "                      upsample=True, \n",
    "                      verbose=0)\n",
    "    best_params = grid.best_params_\n",
    "    single_best_score = grid.best_score_\n",
    "\n",
    "    print('  Gridsearch evaluated best score %s' % (single_best_score))\n",
    "    print('    Running %d iterations on best classifier %s ...' % (n, best_params))\n",
    "\n",
    "    all_scores = []\n",
    "    all_feature_importances = []\n",
    "    all_dropcol_feature_importances = []\n",
    "    for i in np.arange(n):\n",
    "        forest = RandomForestClassifier(oob_score=True)\n",
    "        forest.set_params(**best_params)\n",
    "\n",
    "        scores = run_cross_val_score(forest, \n",
    "                          X, y,  \n",
    "                          verbose=0)\n",
    "    #    print(scores)\n",
    "        scores_df = pd.DataFrame(scores)\n",
    "        #print(scores_df)\n",
    "        #print(scores_df.columns)\n",
    "        all_scores.append(scores_df)\n",
    "\n",
    "    X_ = pd.DataFrame(X, columns=subject_features_nophase)\n",
    "    y_ = pd.DataFrame(y)\n",
    "    for i in np.arange(300):\n",
    "        # alternative computation for feature importance\n",
    "        all_dropcol_feature_importances.append(dropcol_importances(forest, X_, y_, RANDOM_STATE+i))\n",
    "\n",
    "    all_scores = pd.concat(all_scores)\n",
    "    all_feature_importances = pd.DataFrame(all_feature_importances, columns=subject_features_nophase)\n",
    "    all_dropcol_features_importances = pd.DataFrame(all_dropcol_feature_importances, columns=subject_features_nophase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#print(all_scores)\n",
    "all_scores_ = all_scores.drop(['fit_time', 'score_time'], axis=1).T\n",
    "final = pd.DataFrame(index=all_scores_.index)\n",
    "\n",
    "final['means'] = all_scores_.mean(axis=1)\n",
    "final['std'] = all_scores_.std(axis=1)\n",
    "final['sem'] = all_scores_.sem(axis=1)\n",
    "final['confidence'] = all_scores_.apply(lambda row : 2*(np.mean(row) - st.t.interval(0.95, len(row)-1, loc=np.mean(row), scale=st.sem(row))[0]) , axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "final_fi = all_dropcol_features_importances.T\n",
    "final_fi['means'] = final_fi.mean(axis=1)\n",
    "final_fi['std'] = final_fi.std(axis=1)\n",
    "final_fi['sem'] = final_fi.sem(axis=1)\n",
    "final_fi['confidence'] = final_fi.apply(lambda row : 2*(np.mean(row) - st.t.interval(0.95, len(row)-1, loc=np.mean(row), scale=st.sem(row))[0]) , axis = 1)\n",
    "\n",
    "\n",
    "plot_importance('Columns Drop', \n",
    "                final_fi['means'],\n",
    "                final_fi['confidence'],\n",
    "                subject_features_nophase, \n",
    "                sort=False)\n",
    "\n",
    "\n",
    "final_fi_ = all_feature_importances.T\n",
    "final_fi_['means'] = final_fi_.mean(axis=1)\n",
    "final_fi_['std'] = final_fi_.std(axis=1)\n",
    "final_fi_['sem'] = final_fi_.sem(axis=1)\n",
    "final_fi_['confidence'] = final_fi_.apply(lambda row : 2*(np.mean(row) - st.t.interval(0.95, len(row)-1, loc=np.mean(row), scale=st.sem(row))[0]) , axis = 1)\n",
    "\n",
    "\n",
    "plot_importance('Gini', \n",
    "                final_fi_['means'],\n",
    "                final_fi_['confidence'],\n",
    "                subject_features_nophase, \n",
    "                sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score max_features n_estimators max_depth min_samples_leaf\n",
      "0  0.878095         None          100      None                1\n",
      "3  0.837778         auto          100      None                1\n",
      "6  0.825079         auto          100      None                1\n",
      "1  0.815556         None          100         5                1\n",
      "2  0.813356         None          100      None                1\n",
      "5  0.810635         auto          100      None                1\n",
      "9  0.785556         auto          100         5                1\n",
      "4  0.783039         auto          100         5                1\n",
      "8  0.773968         None          100         5                1\n",
      "7  0.761451         auto          100         5                1\n"
     ]
    }
   ],
   "source": [
    "unpacked = [[p[key] for p in best_params] for key in best_params[0].keys()]\n",
    "df = pd.DataFrame(data=np.vstack((scores, unpacked))).T\n",
    "df.columns=['score', 'max_features', 'n_estimators', 'max_depth', 'min_samples_leaf']\n",
    "print(df.sort_values(by=['score'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            score max_features  n_estimators  max_depth  min_samples_leaf\n",
      "count   10.000000            6            10          5                10\n",
      "unique  10.000000            1             1          1                 1\n",
      "top      0.783039         auto           100          5                 1\n",
      "freq     1.000000            6            10          5                10\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_f1_macro    0.646716\n",
      "dtype: float64\n",
      "0     0.099310\n",
      "1     0.150313\n",
      "2     0.114089\n",
      "3     0.091315\n",
      "4     0.136336\n",
      "5     0.121339\n",
      "6     0.091315\n",
      "7     0.136336\n",
      "8     0.121339\n",
      "9     0.091315\n",
      "10    0.136336\n",
      "11    0.121339\n",
      "12    0.105714\n",
      "13    0.111815\n",
      "14    0.114223\n",
      "15    0.103319\n",
      "16    0.121836\n",
      "17    0.120246\n",
      "18    0.103319\n",
      "19    0.121836\n",
      "20    0.120246\n",
      "21    0.103319\n",
      "22    0.121836\n",
      "23    0.120246\n",
      "24    0.115931\n",
      "25    0.150313\n",
      "26    0.114089\n",
      "27    0.119221\n",
      "28    0.136336\n",
      "29    0.121339\n",
      "30    0.119221\n",
      "31    0.136336\n",
      "32    0.121339\n",
      "33    0.119221\n",
      "34    0.136336\n",
      "35    0.121339\n",
      "36    0.099310\n",
      "37    0.150313\n",
      "38    0.114089\n",
      "39    0.091315\n",
      "40    0.136336\n",
      "41    0.121339\n",
      "42    0.091315\n",
      "43    0.136336\n",
      "44    0.121339\n",
      "45    0.091315\n",
      "46    0.136336\n",
      "47    0.121339\n",
      "Name: std_test_f1_macro, dtype: float64\n",
      "0     0.009862\n",
      "1     0.022594\n",
      "2     0.013016\n",
      "3     0.008338\n",
      "4     0.018588\n",
      "5     0.014723\n",
      "6     0.008338\n",
      "7     0.018588\n",
      "8     0.014723\n",
      "9     0.008338\n",
      "10    0.018588\n",
      "11    0.014723\n",
      "12    0.011175\n",
      "13    0.012503\n",
      "14    0.013047\n",
      "15    0.010675\n",
      "16    0.014844\n",
      "17    0.014459\n",
      "18    0.010675\n",
      "19    0.014844\n",
      "20    0.014459\n",
      "21    0.010675\n",
      "22    0.014844\n",
      "23    0.014459\n",
      "24    0.013440\n",
      "25    0.022594\n",
      "26    0.013016\n",
      "27    0.014214\n",
      "28    0.018588\n",
      "29    0.014723\n",
      "30    0.014214\n",
      "31    0.018588\n",
      "32    0.014723\n",
      "33    0.014214\n",
      "34    0.018588\n",
      "35    0.014723\n",
      "36    0.009862\n",
      "37    0.022594\n",
      "38    0.013016\n",
      "39    0.008338\n",
      "40    0.018588\n",
      "41    0.014723\n",
      "42    0.008338\n",
      "43    0.018588\n",
      "44    0.014723\n",
      "45    0.008338\n",
      "46    0.018588\n",
      "47    0.014723\n",
      "Name: std_test_f1_macro, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dfu = pd.DataFrame(grid.cv_results_)\n",
    "dfu[['mean_test_f1_macro', 'std_test_f1_macro']]\n",
    "print(np.mean(dfu[['mean_test_f1_macro']]))\n",
    "print(dfu['std_test_f1_macro'])\n",
    "print(np.square(dfu['std_test_f1_macro']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(means): 39.6666666667\n",
      "std(means): 8.95048105473\n",
      "tscore: 4.30265272991\n",
      "95% CI = [17.4324391395,61.9008941939]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>row_mean</th>\n",
       "      <th>row_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exp1</th>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>2.943920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp2</th>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>49.333333</td>\n",
       "      <td>3.091206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp3</th>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>2.494438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2   row_mean   row_std\n",
       "exp1  34  41  39  38.000000  2.943920\n",
       "exp2  45  51  52  49.333333  3.091206\n",
       "exp3  29  31  35  31.666667  2.494438"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as st \n",
    "\n",
    "data = pd.DataFrame({\n",
    "     \"exp1\":[34, 41, 39] \n",
    "    ,\"exp2\":[45, 51, 52]\n",
    "    ,\"exp3\":[29, 31, 35]\n",
    "}).T\n",
    "\n",
    "data.loc[:,\"row_mean\"] = data.mean(axis=1)\n",
    "data.loc[:,\"row_std\"] = data.std(axis=1)\n",
    "\n",
    "mean_of_means = data.row_mean.mean()\n",
    "std_of_means = data.row_mean.std()\n",
    "tscore = st.t.ppf(1-0.025, data.shape[0]-1)\n",
    "\n",
    "print(\"mean(means): {}\\nstd(means): {}\\ntscore: {}\".format(mean_of_means,std_of_means,tscore))\n",
    "\n",
    "lower_bound = mean_of_means - (tscore*std_of_means/(data.shape[0]**0.5))\n",
    "upper_bound = mean_of_means + (tscore*std_of_means/(data.shape[0]**0.5))\n",
    "\n",
    "\n",
    "print(\"95% CI = [{},{}]\".format(lower_bound,upper_bound))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
